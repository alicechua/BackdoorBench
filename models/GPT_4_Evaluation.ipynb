{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wt7OndSpFt0l"
      },
      "outputs": [],
      "source": [
        "import os, re, json\n",
        "from tqdm.auto import tqdm\n",
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=userdata.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "SYSTEM = (\n",
        "    \"You are a precise causal reasoning assistant. \"\n",
        "    \"Given a directed graph and textual premises, decide whether the stated hypothesis is TRUE (1) or FALSE (0). \"\n",
        "    \"Only output a single digit: 0 or 1.\"\n",
        ")\n",
        "\n",
        "def build_messages_openai(ex):\n",
        "    graph_str  = json.dumps(ex[\"graph\"], sort_keys=True)\n",
        "    premise    = (ex.get(\"premise\",\"\") or \"\").strip()\n",
        "    hypothesis = (ex.get(\"hypothesis\",\"\") or \"\").strip()\n",
        "\n",
        "    user_text = (\n",
        "        \"### Task:\\nDecide if the hypothesis follows from the graph and premise.\\n\\n\"\n",
        "        f\"### Graph (JSON):\\n{graph_str}\\n\\n\"\n",
        "        f\"### Premise:\\n{premise}\\n\\n\"\n",
        "        f\"### Hypothesis:\\n{hypothesis}\\n\\n\"\n",
        "        \"### Answer:\\n\"\n",
        "    )\n",
        "\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM},\n",
        "        {\"role\": \"user\",   \"content\": user_text},\n",
        "    ]\n",
        "\n",
        "def predict_label_gpt4(ex, model_name=\"gpt-4.1-mini\"):\n",
        "    messages = build_messages_openai(ex)\n",
        "\n",
        "    resp = client.responses.create(\n",
        "        model=model_name,\n",
        "        input=[{\"role\": m[\"role\"], \"content\": m[\"content\"]} for m in messages],\n",
        "        max_output_tokens=16,\n",
        "        temperature=0,\n",
        "    )\n",
        "\n",
        "    # Extract the text output\n",
        "    text = resp.output[0].content[0].text.value  # SDK v1 Responses API shape\n",
        "\n",
        "    m = re.search(r\"[01]\", text)\n",
        "    if m:\n",
        "        return int(m.group(0)), text\n",
        "    return None, text\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "for ex in tqdm(small_test_raw, desc=\"Evaluating GPT-4.1-mini\", unit=\"example\"):\n",
        "    pred, text = predict_label_gpt4(ex)\n",
        "    if pred is not None:\n",
        "        total += 1\n",
        "        correct += int(pred == int(ex[\"label\"]))\n",
        "\n",
        "print(f\"GPT-4.1-mini accuracy on test subset: {correct}/{total} = {correct/total:.3f}\")\n"
      ]
    }
  ]
}