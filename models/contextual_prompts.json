{"id": "gen_1", "kind": "general", "text": "As you read, focus on understanding how a backdoor adjustment set functions to remove confounding in causal inference. Pay attention to the conditions that define a valid adjustment set—blocking noncausal backdoor paths and avoiding descendants of the treatment—and how these relate to the intuition of making treated and untreated groups comparable. Reflect on the balance between blocking confounders and avoiding bias from conditioning on colliders or mediators, and how the adjustment formula expresses causal identifiability once such a set is found."}
{"id": "gen_2", "kind": "general", "text": "As you read the passage on backdoor adjustment in causal DAGs, interrogate it from multiple angles: restate the core claim about what a backdoor set is and why adjustment identifies the causal effect, and identify the implicit assumptions that make these claims true. Map these assumptions to potential risks—what happens if the DAG is misspecified, descendants of X are included, colliders are conditioned on, or positivity is violated? Stress-test the argument by imagining variants such as hidden confounders or colliders and evaluate whether the proposed Z still blocks all backdoor paths. If Z is said to be minimal, consider whether removing one variable would reopen a path. Compare this DAG-based reasoning with alternative perspectives like the potential-outcomes framework or the challenges faced by practitioners dealing with finite samples and measurement error. Reflect on edge cases such as conditioning on mediators, selection bias, or rare strata that could distort identification. Explore alternative strategies like front-door adjustment, instrumental variables, or randomized trials when backdoor sets fail. Finally, connect identification to estimation—what modeling or diagnostic choices affect robustness—and conclude by judging whether backdoor adjustment via your chosen Z is persuasive given the assumptions and data context."}
{"id": "gen_3", "kind": "general", "text": "As you study the concept of a backdoor adjustment set in causal inference, think about how this idea connects to your existing understanding of confounding, correlation vs. causation, and statistical control. How does the notion of “blocking backdoor paths” relate to the way you’ve previously handled bias or spurious associations in data analysis or experimental design? Reflect on a time when conditioning on certain variables clarified or distorted your conclusions—how might identifying a minimal sufficient backdoor set have changed your interpretation of cause and effect in that situation?"}
{"id": "gen_4", "kind": "general", "text": "After reading the explanation of a backdoor adjustment set in causal inference, summarize the main ideas in your own words. Focus on explaining what a backdoor adjustment set is, why it is important for identifying causal effects, and how it works conceptually and graphically. Try to restate the criteria and intuition without relying on the original phrasing—synthesize the information as if you were teaching it to someone new to causal diagrams."}
{"id": "gen_5", "kind": "general", "text": "As you read the explanation of the *backdoor adjustment set* in causal DAGs, compare this concept to related ideas in causal inference—such as *front-door adjustment*, *instrumental variables*, or *propensity score matching*. Identify how each method attempts to control for confounding or isolate causal effects, and highlight the key differences in their assumptions, applicability, and graphical criteria. Consider how the role of conditioning on certain variables (e.g., confounders, mediators, colliders) changes across these approaches, and reflect on how these distinctions influence causal identifiability and estimation."}

{"id": "neg_fb_1", "kind": "negative", "neg_type": "forbidden_descendant", "text": "Reflect on how the concept of a backdoor adjustment set in causal inference ensures valid estimation of causal effects. Focus on understanding how conditioning on the right set of variables blocks spurious (noncausal) paths between treatment and outcome while preserving the true causal pathway. Pay attention to why variables that are descendants of the treatment—“forbidden descendants”—must be excluded, and how their inclusion can introduce post-treatment bias or distort causal interpretation. Consider how this principle connects to broader ideas in causal reasoning, such as confounding, mediation, and identification strategies."}
{"id": "neg_c_1", "kind": "negative", "neg_type": "collider", "text": "As you read this passage, focus on understanding what a valid backdoor adjustment set is and why it identifies causal effects: how (Z) must block all noncausal backdoor paths from (X) to (Y) without including descendants of (X). Pay special attention to the roles of confounders, mediators, and colliders, and to the “collider trap,” where conditioning on a collider (or its descendant) opens spurious associations instead of removing bias. As you go, trace example DAGs in your mind, decide which variables belong in (Z), and internalize the practical rule: adjust for common causes of (X) and (Y), but do not adjust for colliders or their descendants, even if they seem intuitively relevant."}
{"id": "neg_nm_1", "kind": "negative", "neg_type": "near_miss", "text": "While reading this passage, focus on what makes an adjustment set truly valid in a causal DAG: how backdoor paths arise, how conditioning on the right pre-treatment confounders blocks all noncausal paths from X to Y, and why you must exclude descendants of X and colliders (or their descendants) to avoid bias. Pay special attention to the idea of a minimal sufficient backdoor set and the “near miss” patterns (omitted confounder, forbidden descendant, collider trap, and proxy without control): for each, try to picture the DAG structure, identify which backdoor requirement is violated, and reason about how that specific mistake reintroduces confounding or distorts the causal effect."}